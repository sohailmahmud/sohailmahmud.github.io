<h2 style="text-align: center; margin-top: -150px;"> Research
    <details class="research_details">
        <summary> View research overview</summary>
        <div class="research_details_text">
        <p>🔎 My research focuses on how we can build trustworthy machine-learning systems by making them interpretable. In
            my work, interpretability is grounded seriously via close collaboration with domain experts, e.g. medical
            doctors or cell biologists. These collaborations have given rise to useful methodology, roughly split into two
            areas: (1) building more effective <em>transparent models</em> and (2) improving the trustworthiness of <em>black-box
                models</em>. Going forward, I hope to help bridge the gap between transparent models and black-box models to
            improve real-world healthcare.</p>
        <p>🌳 Whenever possible, building transparent models is the most effective route towards ensuring interpretability.
            Transparent models are interpretable by design, including models such as (concise) decision trees, rule lists,
            and linear models. My work in this area was largely motivated by the problem of <a href="">clinical
                decision-rule development</a>. Clinical decision rules (especially those used in emergency medicine), need
            to be extremely transparent so they can be readily audited and used by physicians making split-second decisions.
            To this end, we have developed methodology for enhancing decision trees. For example, replacing the standard
            CART algorithm with a novel <a href="https://arxiv.org/abs/2201.11931">greedy algorithm</a> for tree-sums can
            substantially improve predictive performance without sacrificing predictive performance. Additionally, <a
                    href="https://arxiv.org/abs/2202.00858">hierarchical regularization</a> can improve the predictions of
            an already fitted model without altering its interpretability. Despite their effectiveness, transparent models
            such as these often get overlooked in favor of black-box models; to address this issue, we&#39;ve spent a lot of
            time curating <a href="https://github.com/sohailmahmud/imodels">imodels</a>, an open-source package for fitting
            state-of-the-art transparent models.</p>
        <p>🌀 My second line of my work focuses on interpreting and improving black-box models, such as neural networks, for
            the cases when a transparent model simply can&#39;t predict well enough. Here, I work closely on real-world
            problems such as analyzing imaging data from <a href="">cell biology</a> and <a
                    href="https://arxiv.org/abs/2003.01926">cosmology</a>. Interpretability in these contexts demands more
            nuanced information than standard notions of &quot;feature importance&quot; common in the literature. As a result, we
            have developed methods to characterize and summarize the <a
                    href="https://arxiv.org/abs/1806.05337">interactions</a> in a neural network, particularly in <a
                    href="https://arxiv.org/abs/2003.01926">transformed domains</a> (such as the Fourier domain), where
            domain interpretations can be more natural. I&#39;m particularly interested in how we can ensure that these
            interpretations are <em>useful</em>, either by using them to <a
                    href="http://proceedings.mlr.press/v119/rieger20a.html">embed prior knowledge</a> into a model or
            identify when it can be trusted.</p>
        <p>🤝 There is a lot more work to do on bridging the gap between transparent models and black-box models in the real
            world. One promising avenue is distillation, whereby we can use a black-box model to build a better transparent
            model. For example, in <a
                    href="https://proceedings.neurips.cc/paper/2021/hash/acaa23f71f963e96c8847585e71352d6-Abstract.html">one
                work</a> we were able to distill state-of-the-art neural networks in cell-biology and cosmology into
            transparent wavelet models with &lt;40 parameters. Despite this huge size reduction, these models actually <em>improve</em>
            prediction performance. By incorporating close domain knowledge into models and the way we approach problems, I
            believe interpretability can help unlock many benefits of machine-learning for improving healthcare and science.
        </p>
            </div>
    </details>
        </h2>
    
    <div class="iframe-box" style="margin-top: -30px">
        <iframe class="iframe"
                src="https://docs.google.com/presentation/d/e/2PACX-1vSj1GlDHEk8AhlYSL9eRb0sFHDF-QqvgS9SckgeekmzTtYdNQWGalhOR5MlmfKsgyW3TtOYq-SpyPkA/embed?rm=minimal"
                frameborder="0" width="100%" height="auto" allowfullscreen="true" mozallowfullscreen="true"
                webkitallowfullscreen="true">
        </iframe>
    </div>
    
    <!--<table>-->
    <!--    <tr>-->
    <!--        <th>-->
    <!--            <strong style="font-size:21px;"> interpretable ml </strong> <br/>-->
    <!--            <a href="/blog/research/interp"> what is interpretability? </a> <br/>-->
    <!--            <a href="/blog/research/interp_eval"> evaluating interpretability </a>-->
    <!--        </th>-->
    <!--&lt;!&ndash;        <th><strong style="font-size:21px;"> interpretability applications </strong></th>&ndash;&gt;-->
    <!--        <th>-->
    <!--            <strong style="font-size:21px;"> science </strong> <br/>-->
    <!--            <a href="/blog/research/connectomics"> Connectomics</a> <br/>-->
    <!--            <a href="/blog/research/neural_coding" > neural coding </a>-->
    <!--        </th>-->
    <!--&lt;!&ndash;        <th>&ndash;&gt;-->
    <!--&lt;!&ndash;            <strong style="font-size:21px;"> ml theory </strong>&ndash;&gt;-->
    <!--&lt;!&ndash;        </th>&ndash;&gt;-->
    <!--    </tr>-->
    <!--    <tr>-->
    <!--        <th><br/></th>-->
    <!--    </tr>-->
    <!--    <tr>-->
    <!--        <th><img src="{{ site.baseurl }}/assets/img/alexnet.png" class="research_thumb"></th>-->
    <!--&lt;!&ndash;        <th><img src="{{ site.baseurl }}/assets/img/cosmo.png" class="research_thumb"></th>&ndash;&gt;-->
    <!--        <th><img src="{{ site.baseurl }}/assets/img/neuron.gif" class="research_thumb"></th>-->
    <!--&lt;!&ndash;        <th><img src="{{ site.baseurl }}/assets/img/complexity.png" class="research_thumb"></th>&ndash;&gt;-->
    <!--    </tr>-->
    <!--</table>-->
    
    <!--<br/>-->
    
    <script>
        $(document).ready(function () {
            $('#research_table').DataTable({
                "order": [[0, "desc"]],
                "aLengthMenu": [[15, -1], [15, "All"]],
                "pageLength": "15",
                dom: 'Bfrtip',
                buttons: [
                    {
                        text: '🔎 software engineering',
                        action: function (e, dt, node, config) {
                            $(".dataTables_wrapper input").val(function () {
                                return this.value + "🔎";
                            });
                            // $(".dataTables_wrapper input").submit();
                        }
                    },
                    {
                        text: '🌀 deep learning',
                        action: function (e, dt, node, config) {
                            $(".dataTables_wrapper input").val(function () {
                                return this.value + "🌀";
                            });
                            // $(".dataTables_wrapper input").val("🌀");
                        }
                    },
                    {
                        text: '⛓️ blockchain',
                        action: function (e, dt, node, config) {
                            $(".dataTables_wrapper input").val(function () {
                                return this.value + "🌳";
                            });
                            // $(".dataTables_wrapper input").val("🌳");
                        }
                    },
                    {
                        text: '💻 open-source ML',
                        action: function (e, dt, node, config) {
                            $(".dataTables_wrapper input").val(function () {
                                return this.value + "💻";
                            });
                            // $(".dataTables_wrapper input").val("💻");
                        }
                    },
                    {
                        text: '🧠',
                        action: function (e, dt, node, config) {
                            $(".dataTables_wrapper input").val(function () {
                                return this.value + "🧠";
                            });
                            // $(".dataTables_wrapper input").val("🧠");
                        }
                    },
                ]
            });
        });
    </script>
    
    <table id="research_table" class="display" style="width:100%">
        <thead>
        <tr>
            <th>year</th>
            <th>title</th>
            <th>authors</th>
            <th>tags</th>
            <th>paper</th>
            <th>code</th>
            <th>misc</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td class="center">'22</td>
            <td>developing reliable clinical decision rules: a case study in identifying blunt abdominal trauma in
                children
            </td>
            <td>kornblith*, singh* et al.</td>
            <td class="med">🔎🌳💊</td>
            <td class="center"><a href="#">SAEM abstract</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/iai-clinical-decision-rule"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1mxzGE0MkNZnzbIimDP8Kyq8oLfVSmHrOCKDPhiBPMz4/present?slide=id.p"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Interpretable deep learning for accurate molecular partner prediction in clathrin-mediated endocytosis</td>
            <td>singh*, li*, et al.</td>
            <td class="med">🔎🌀🦠</td>
            <td class="center">in prep</td>
            <td class="big"><a href="https://github.com/sohailmahmud/auxilin-prediction"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Fast Interpretable Greedy-Tree Sums (FIGS)</td>
            <td>tan*, singh*, nasseri, agarwal, & yu</td>
            <td class="med">🔎🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2201.11931">arxiv</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/sohailmahmud/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://demos.sohails.tech/figs/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Hierarchical shrinkage: improving accuracy and interpretability of tree-based methods</td>
            <td>agarwal*, tan*, ronen, singh, & yu</td>
            <td class="med">🔎🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2202.00858">arxiv</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/sohailmahmud/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://demos.csinva.io/shrinkage/"><i class="fa fa-home fa-fw"></i></a>
                <!--            <a href="https://docs.google.com/presentation/d/1ReJ3Lqh4VZqpu6X6sP47f6Re6PvLIX9ZRAdjb8ZhFXE/present?slide=id.p"><i-->
                <!--                    class="fa fa-desktop fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>VeridicalFlow: a Python package for building trustworthy data science pipelines with PCS</td>
            <td>duncan*, kapoor*, agarwal*, singh*, & yu</td>
            <td class="med">💻🔍</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03895">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/sohailmahmud/veridical-flow"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>imodels: a python package for fitting interpretable models</td>
            <td>singh*, nasseri*, et al.</td>
            <td class="med">💻🔍🌳</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03192">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2022/02/02/imodels/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Adaptive wavelet distillation from neural networks through interpretations</td>
            <td>ha, singh, et al.</td>
            <td class="med">🔍🌀🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/2107.09145">neurips</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/sohailmahmud/adaptive-wavelet-distillation"><i
                    class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2021/09/28/wavelet/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Matched sample selection with GANs for mitigating attribute confounding</td>
            <td>singh, balakrishnan, & perona</td>
            <td class="med">🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2103.13455">cvpr workshop</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/sohailmahmud/matching-with-gans"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Revisiting complexity and the bias-variance tradeoff</td>
            <td>dwivedi*, singh*, yu & wainwright</td>
            <td class="med">🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/2006.10189">topml workshop</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/mdl-complexity"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Curating a COVID-19 data repository and forecasting county-level death counts in the United States</td>
            <td>altieri et al.</td>
            <td class="med">🔎🦠</td>
            <td class="center"><a href="https://arxiv.org/abs/2005.07882">hdsr</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/covid19-severity-prediction"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="#"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://covidseverity.com/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>transformation importance with applications to cosmology</td>
            <td>singh*, ha*, lanusse, boehm, liu & yu</td>
            <td class="med">🔎🌀🌌</td>
            <td class="center"><a href="https://arxiv.org/abs/2003.01926">iclr workshop (spotlight)</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/transformation-importance"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>interpretations are useful: penalizing explanations to align neural networks with prior knowledge</td>
            <td>rieger, singh, murdoch & yu</td>
            <td class="med">🔎🌀</td>
            <td class="center"><a href="http://proceedings.mlr.press/v119/rieger20a.html">icml</a>
            </td>
            <td class="big"><a href="https://github.com/laura-rieger/deep-explanation-penalization"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a href="https://icml.cc/virtual/2020/poster/5914"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>hierarchical interpretations for neural network predictions</td>
            <td>Singh*, Murdoch*, & Yu</td>
            <td class="med">🔍🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/1806.05337">ICLR</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/acd"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a>
                <!--            <a href="{{site.baseurl}}/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>interpretable machine learning: definitions, methods, and applications</td>
            <td>Murdoch*, Singh*, et al.</td>
            <td class="med">🔍🌳🌀</td>
            <td class="center"><a href="https://arxiv.org/abs/1901.04592">pnas</a></td>
            <td></td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a>
                <!--            <a  href="{{site.baseurl}}/assets/write_ups/utokyo_19_interp_poster.pdf"><i  class="fa fa-picture-o fa-fw"></i></a></td>-->
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>disentangled attribution curves for interpreting random forests and boosted trees</td>
            <td>devlin, singh, murdoch & yu</td>
            <td class="med">🔍🌳</td>
            <td class="center"><a href="https://arxiv.org/abs/1905.07631">arxiv</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/disentangled_attribution_curves"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td></td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>large scale image segmentation with structured loss based deep learning for connectome reconstruction</td>
            <td>Funke*, Tschopp*, et al.</td>
            <td class="med">🧠🌀</td>
            <td class="center"><a href="https://ieeexplore.ieee.org/abstract/document/8364622/">TPAMI</a></td>
            <td class="big"><a href="https://github.com/sohailmahmud/mala"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="{{site.baseurl}}/assets/write_ups/singh_15_rf_segmentation.pdf"><i
                        class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>linearization of excitatory synaptic integration at no extra cost</td>
            <td>Morel, Singh, & Levy</td>
            <td class="med">🧠</td>
            <td class="center"><a href="http://rdcu.be/FDUo">J Comp Neuro</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a consensus layer V pyramidal neuron can sustain interpulse-interval coding</td>
            <td>Singh & Levy</td>
            <td class="med">🧠</td>
            <td class="center"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0180839">Plos
                One</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a constrained, weighted-l1 minimization approach for joint discovery of heterogeneous neural connectivity
                graphs
            </td>
            <td>Singh, Wang, & Qi</td>
            <td class="med">🧠</td>
            <td class="center"><a href="https://arxiv.org/abs/1709.04090">neurips Workshop</a></td>
            <td class="big"><a href="https://cran.r-project.org/web/packages/simule/index.html"><i
                    class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="#"><i
                    class="fa fa-desktop fa-fw"></i></a>,
                <!--            <a-->
                <!--                href="{{site.baseurl}}/assets/write_ups/wsimule_17_nips_poster.pdf"><i-->
                <!--                class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
        </tbody>
    
    </table>
    
    <style>
        .big {
            font-size: large;
            text-align: center;
        }
    
        .med {
            font-size: medium;
            text-align: center;
        }
    
        td {
            text-align: left;
        }
    
        .center {
            text-align: center;
        }
    
        .dt-button span {
            color: white;
            font-family: Lora, "Helvetica Neue", Helvetica, Arial, sans-serif;
    
        }
    </style>
    